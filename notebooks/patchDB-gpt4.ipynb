{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T01:39:31.128281Z",
     "iopub.status.busy": "2025-05-04T01:39:31.127400Z",
     "iopub.status.idle": "2025-05-04T01:39:34.911725Z",
     "shell.execute_reply": "2025-05-04T01:39:34.910662Z",
     "shell.execute_reply.started": "2025-05-04T01:39:31.128204Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import openai, os\n",
    "from openai import OpenAI\n",
    "import string\n",
    "import random\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T01:39:34.913795Z",
     "iopub.status.busy": "2025-05-04T01:39:34.913520Z",
     "iopub.status.idle": "2025-05-04T01:39:35.710920Z",
     "shell.execute_reply": "2025-05-04T01:39:35.709870Z",
     "shell.execute_reply.started": "2025-05-04T01:39:34.913774Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15728\\AppData\\Local\\Temp\\ipykernel_21080\\807549141.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({\"category\": label2id})\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(r'../datasets/patch_db.json', encoding='utf_8_sig')\n",
    "df.dropna(inplace=True)\n",
    "label2id={'non-security':0,'security':1}\n",
    "df = df.replace({\"category\": label2id})\n",
    "df.rename(columns={'category':'label','diff_code':'diff','commit_message':'message'},inplace=True)\n",
    "df = df.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T01:39:35.712106Z",
     "iopub.status.busy": "2025-05-04T01:39:35.711908Z",
     "iopub.status.idle": "2025-05-04T01:39:35.739105Z",
     "shell.execute_reply": "2025-05-04T01:39:35.738187Z",
     "shell.execute_reply.started": "2025-05-04T01:39:35.712086Z"
    }
   },
   "outputs": [],
   "source": [
    "id2label={0:'Negative',1:'Positive'}\n",
    "df.rename(columns={'label':'labels','diff':'diffs','message':'msgs'},inplace=True)\n",
    "df = df.replace({\"labels\": id2label})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T01:39:35.740055Z",
     "iopub.status.busy": "2025-05-04T01:39:35.739867Z",
     "iopub.status.idle": "2025-05-04T01:39:35.750242Z",
     "shell.execute_reply": "2025-05-04T01:39:35.749295Z",
     "shell.execute_reply.started": "2025-05-04T01:39:35.740034Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=\"sk-bIHAQMOPc0mMMFKgkvZE9sMyggQvA6zi1SR6oq7uSyZRQpc5\",  # 或者 os.environ[\"OPENAI_API_KEY\"]\n",
    "    base_url=\"https://sg.uiuiapi.com/v1\",  # 注意最好加 /v1,\n",
    "    # model=\"gpt-4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-4-0301\"):\n",
    "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model == \"gpt-4-0301\":  # note: future models may deviate from this\n",
    "        num_tokens = 0\n",
    "        for message in messages:\n",
    "            num_tokens += (\n",
    "                4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "            )\n",
    "            for key, value in message.items():\n",
    "                num_tokens += len(encoding.encode(value))\n",
    "                if key == \"name\":  # if there's a name, the role is omitted\n",
    "                    num_tokens += -1  # role is always required and always 1 token\n",
    "        num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "        return num_tokens\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\n",
    "  See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T01:40:31.994419Z",
     "iopub.status.busy": "2025-05-04T01:40:31.994030Z",
     "iopub.status.idle": "2025-05-04T01:41:21.476640Z",
     "shell.execute_reply": "2025-05-04T01:41:21.474835Z",
     "shell.execute_reply.started": "2025-05-04T01:40:31.994389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper to format the k-shot prompt with:\n",
    "# - prefix\n",
    "# - 1 example from each class\n",
    "# - target text for classification\n",
    "def generate_promot(row):\n",
    "    base_promot = \"\"\"\n",
    "    Please act as a security patch identificator,\n",
    "    categorize patch into two categories: Negative, Positive.\n",
    "    The Negative category corresponds to patches which includes insecure code changes.\n",
    "    The Positive category corresponds to patches which includes secure code changes.\n",
    "    I will provide you with the commit message and code diff for a commit patch,\n",
    "    and you need to give me the category label for this commit patch.\n",
    "    Please avoid any explanations and only provide the category label.\n",
    "    \"\"\"\n",
    "\n",
    "    commit_message_prompt = f\"commit message: {row['msgs']}\\n\"\n",
    "    commit_codediff_prompt = f\"code diff: {row['diffs']}\\n\"\n",
    "\n",
    "    prompt = base_promot + commit_message_prompt + commit_codediff_prompt\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    l, r = 0, len(commit_codediff_prompt) - 1\n",
    "    while l <= r:\n",
    "        mid = (l + r) // 2\n",
    "        prompt = base_promot + commit_message_prompt + commit_codediff_prompt[:mid]\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "        ok = num_tokens_from_messages(messages) < 4096\n",
    "        if ok:\n",
    "            l = mid + 1\n",
    "        else:\n",
    "            r = mid - 1\n",
    "    prompt = base_promot + commit_message_prompt + commit_codediff_prompt[:r]\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Category: Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "# Helper method to prompt OpenAI LLM and get response.\n",
    "def get_response(user_content):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",  # 根据代理方文档修改\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# text = \"\\'How can I change my pin?\\'\"\n",
    "# examples = get_examples(examples_pool)\n",
    "# df = pd.read_csv('dataset.csv')\n",
    "\n",
    "result = []\n",
    "for i, row in val_df.iterrows():\n",
    "    user_content = generate_promot(row)\n",
    "    # print(user_content)\n",
    "    response =  get_response(user_content)\n",
    "    result.append(response)\n",
    "    # print(\"Model classified \", user_content, \" as \", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['result'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26404    Positive\n",
       "3770     Positive\n",
       "4463     Positive\n",
       "8353     Positive\n",
       "3594     Positive\n",
       "           ...   \n",
       "9343     Negative\n",
       "28034    Positive\n",
       "23044    Positive\n",
       "8800     Positive\n",
       "28672    Positive\n",
       "Name: result, Length: 300, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv('patchDB_result.csv',encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 仅保留 result 为 'positive' 或 'negative' 的行\n",
    "# val_df = val_df[val_df['result'].isin(['positive', 'negative'])].copy()\n",
    "\n",
    "# # 打印对齐检查（行数应一致）\n",
    "# print(f\"After filtering, len(result)={len(val_df['result'])}, len(labels)={len(val_df['labels'])}\")\n",
    "\n",
    "# # 比较结果是否一致\n",
    "# comparison = val_df['result'] == val_df['labels']\n",
    "\n",
    "# # 查看不一致的情况\n",
    "# mismatch_df = val_df[~comparison]\n",
    "\n",
    "# print(f\"共有 {len(mismatch_df)} 行不匹配。\")\n",
    "# display(mismatch_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['result'] = val_df['result'].replace({'Category: Positive': 'Positive', 'Positive': 'Positive','Negative':'Negative'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:45:56.697052Z",
     "iopub.status.busy": "2025-05-04T03:45:56.696363Z",
     "iopub.status.idle": "2025-05-04T03:45:56.707264Z",
     "shell.execute_reply": "2025-05-04T03:45:56.705724Z",
     "shell.execute_reply.started": "2025-05-04T03:45:56.696974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7308    0.0918    0.1631       207\n",
      "    Positive     0.3139    0.9247    0.4687        93\n",
      "\n",
      "    accuracy                         0.3500       300\n",
      "   macro avg     0.5223    0.5083    0.3159       300\n",
      "weighted avg     0.6015    0.3500    0.2578       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(val_df['labels'],val_df['result'],digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26404    Positive\n",
       "3770     Positive\n",
       "4463     Positive\n",
       "8353     Positive\n",
       "3594     Positive\n",
       "           ...   \n",
       "9343     Negative\n",
       "28034    Positive\n",
       "23044    Positive\n",
       "8800     Positive\n",
       "28672    Positive\n",
       "Name: result, Length: 300, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['result'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26404    Positive\n",
       "3770     Negative\n",
       "4463     Negative\n",
       "8353     Negative\n",
       "3594     Negative\n",
       "           ...   \n",
       "9343     Negative\n",
       "28034    Positive\n",
       "23044    Negative\n",
       "8800     Negative\n",
       "28672    Positive\n",
       "Name: labels, Length: 300, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
